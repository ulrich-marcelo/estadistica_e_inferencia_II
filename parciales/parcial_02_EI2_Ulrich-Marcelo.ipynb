{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parcial 2 Estadistica e Inferencia II\n",
    "\n",
    "Alumno: Marcelo Gabriel Ulrich\n",
    "\n",
    "Fecha: 08/10/24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "Los siguientes enunciados son falsos. justifique.\n",
    "\n",
    "a) La distribución predictiva a posteriori representa la distribución conjunta de parámetros en un\n",
    "modelo Bayesiano.\n",
    "\n",
    "b) Una prueba predictiva a priori consiste en comparar la distribución predictiva a priori con la\n",
    "distribución predictiva a posteriori.\n",
    "\n",
    "c) Un valor p Bayesiano es la probabilidad de que la hipótesis nula sea verdadera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) La distribucion predictiva a posteriori en realidad representa la distribucion de los datos que genera el modelo dados los datos ya vistos. La presencia de estos datos ya vistos hace que se actualicen las creencias previas (priors) de los parametros del modelo, usando asi los posteriors (de ahi el nombre, a posteriori). \n",
    "\n",
    "Su formula es\n",
    "$$p(\\tilde{y} | y) = \\int p(\\tilde{y} | \\theta) * p(\\theta | y) d\\theta$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Una prueba predictiva a priori en realidad consiste en comparar la distribucion predictiva a prior con valores teoricos de referencia (ejemplo: maximos, minimos, valores esperados, mediciones antiguas, etc.) Esto se hace para ver si el modelo puede, sin ver nuestros datos, predecir valores \"parecidos\" (que tengan sentido en el contexto en el que usamos el modelo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) El valor P Bayesiano es la probabilidad de que, dado un estadistico como puede ser la media, o la varianza, datos observados y predicciones; este estadistico para las predicciones sea menor al de los observados dadas las predicciones generadas. Su definicion formal es\n",
    "$$ p(T_{\\text{sim}} \\leq T_{\\text{obs}} | \\tilde{y} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "El criterio de información de Akaike (AIC) y el Widely applicable Information Criterion\n",
    "(WAIC) son estimadorres de la capacidad predictiva de un modelo.\n",
    "\n",
    "a) ¿Cuales son los dos términos que componen el AIC?\n",
    "\n",
    "b) ¿En qué se diferencia WAIC de AIC y qué ventajas tiene WAIC sobre AIC?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) AIC esta compuesto por dos terminos: la log likelihood calculada a partir del valor de MLE para los parametros y un termino que la penaliza en funcion de la cantidad de parametros que tiene el modelo. Esto le permite medir que tan bien predice el modelo (log-likelihood) penalizando los modelos grandes que suelen conducir al overfitting.\n",
    "\n",
    "b) El problema principal de AIC es que no es bayesiano: como dije antes, usa la likelihood en funcion del valor de MLE para los parametros. Como en el universo bayesiano usamos priors y posteriors para obtener mas informacion, surge WAIC. \n",
    "\n",
    "Las principales diferencias con AIC son:\n",
    "- En vez de la log-likelihood usa el valor ELPD (que si es bayesiano ya que contempla la posterior)\n",
    "- No usa la cantidad de parametros como penalizador, sino otra cantidad cuya justificacion teorica no vimos jeje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "Pareto-smoothed importance sampling leave-one-out cross-validation (PSIS-LOO-CV)\n",
    "(o LOO de forma abreviada) es un método para evaluar la calidad de un modelo.\n",
    "\n",
    "a) ¿En el contexto del modelado Bayesiano, en que casos se prefiere AIC por sobre LOO?\n",
    "\n",
    "b) LOO, es un método de validación cruzada que no requiere el ajuste repetido del modelo.\n",
    "\n",
    "Explique el funcionamiento de este método y como es esto posible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Nunca, AIC no se usa por no ser bayesiano.\n",
    "\n",
    "En el caso de LOO vs WAIC, entiendo que como LOO hace un muestreo de importancia (importance sampling, no se la traduccion exacta) para hacer una validacion cruzada leave-one-out (es decir, hacer una validacion cruzada donde el tamano de los subsets de datos es 1), a veces los datos que deja fuera tienen un peso importante en la distribucion, por lo que, en condiciones por fuera de la que habilitan a usar el Pareto-smoothing, puede ser preferible usar WAIC antes que LOO.\n",
    "\n",
    "Por fuera de esos casos en los que coinciden pesos importantes (quizas en muestras chicas) y la imposibilidad de hacer pareto-smoothing, siempre es mejor usar LOO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) LOO es espectacular porque hace validacion cruzada loo (explicado en el a.) sin tener que ajustar reiteradas veces el modelo.\n",
    "\n",
    "Al hacer validacion cruzada se suele ajustar el modelo para cada subset de datos que se deja fuera, por lo que hacer LOO-CV (cuya cantidad de subsets es N, dados N datos) suele ser costoso. Para esquivar este problema, con LOO se hace un muestreo de importancia (donde basicamente aproximamos una distribucion a partir de otra mas facil de calcular).\n",
    "\n",
    "Para calcular las posteriors de todos los LOO-CV (es decir, las $p(\\theta | y_{-i})$) hace muesto de importancia con respecto a la posterior total $p(\\theta | y)$ que ya tenemos calculada. Por propiedades matematicas, este muestreo de importancia termina siendo simplemente un conjunto de $\\frac{1}{p(y_i | \\theta)}$, para cada $y_i$ de los datos, valores que ya los tenemos por haber ajustado el modelo.\n",
    "\n",
    "Desarrollando un poco mas el problema planteado en a), el problema que tiene LOO es que, para hacer meustreo de importancia, la condicion optima es que la distribucion a samplear (la del numerador) sea mas estrecha que la del denominador (la que usamos de referencia, en este caso la posterior total). Para el caso que nos compete, las $p(\\theta | y_{-i})$, al tener un dato menos que la posterior total, suelen ser mas anchas. Esto puede traer complicaciones en casos donde, quizas por tener pocos datos o quizas por tener distribuciones con puntos muy influyentes, esta diferencia genere pesos \"pesados\", que modifiquen mucho mi aproximacion resultante.\n",
    "\n",
    "Afortunadamente, en la mayoria de los casos, se puede aplicar un suavizado con una distirbucion de Pareto, mitigando estos efectos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejericio 4\n",
    "Métodos de Inferencia Bayesiana.\n",
    "\n",
    "a) ¿Por qué es necesario el uso de métodos numéricos de inferencia Bayesiana?\n",
    "\n",
    "b) ¿Cuál es la principal diferencia del algoritmo de Metropolis-Hastings vs el algoritmo de Monte\n",
    "Carlo Hamiltoniano?\n",
    "\n",
    "c) ¿Qué ventajas prácticas tiene el método de Monte Carlo Hamiltoniano sobre Metropolis-\n",
    "Hastings?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) En inferencia bayesiana es necesario el uso de metodos numericos ya que, debido a que para realizar inferencia bayesiana hay que resolver intergrales (generalmente de muchas dimensiones), lo cual es muy dificil (a veces imposible) de manera analitica, se utilizan aproximaciones mediante metodos numericos, que hacen que las distribuciones sean mas facilmente calculables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) La principal diferencia entre Metropolis-Hastings y Monte-Carlo Hamiltoniano es que MH es un metodo aleatorio para samplear posteriors, mientras que MCH utiliza derivadas para explorar la distribucion de manera mas optima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Las principal ventaja practica del metodo de Monte Carlo Hamiltoniano sobre Metropolis-Hastings es que, MH suele quedarse atrapado en maximos locales (por como funciona, es menos probable salir de ahi), mientras que MCH, como ademas de usar derivadas usa un momentum, logra escapar de estos maximos locales, perimitiendo una mejor exploracion (y por ende sampleo) de la distribucion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5\n",
    "Métodos de diagnóstico de muestreo.\n",
    "\n",
    "a) El efective sample size (ESS) es una medida de la eficiencia de la cadena de Markov. ¿Qué\n",
    "significa un ESS &quot;bajo&quot;?\n",
    "\n",
    "b) ¿Qué es el R-hat y cómo se calcula?\n",
    "\n",
    "c) ¿Qué significa un R-hat &quot;alto&quot;?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Un ESS bajo en comparacion con el tamano de mi muestra original significa que la cantidad de informacion que aporta mi muestra original es bajo, generalmente debido a la autocorrelacion en el sampleo por cadenas de Markov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) El R-hat es una metrica que nos permite medir que tan parecidas son las cadenas generadas por metodos como MCMC. Se calcula comparando la varianza entre cadenas con la varianza propia de las cadenas, es decir, la varianza inter-cadenas vs varianza intra-cadenas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Un R-hat alto significa que nuestras cadenas no se parecen en nada, en general teniendo que ver con un problema en el sampleo o con nuestro modelo de fondo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 6\n",
    "Modelos lineales generalizados.\n",
    "\n",
    "a) Describa un modelo lineal generalizado y explique que es lo que se &quot;generaliza&quot; respecto de\n",
    "un modelo lineal.\n",
    "\n",
    "b) ¿Cuál es el propósito de la función de enlace (o función inversa de enlace)?\n",
    "\n",
    "c) ¿Qué es un modelo lineal generalizado jerárquico y para que se usa?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Un modelo lineal generalizado consta de dos partes principales: la distribucion de mi variable dependeinte (generalmente llamada y) y el factor lineal que relaciona alguno(s) de mis parametros con la variable dependiente.\n",
    "\n",
    "Lo que se generaliza en los GLMs es:\n",
    "- Por un lado, la distribucion de mi variable dependiente\n",
    "- Por otro lado, lo mas fundamental, es la funcion de enlace inversa, que es una transformacion que se le hace al factor lineal para usarlo como parametro de la distribucion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) La funcion de enlace sirve principalmente para acotar al factor lineal. Como este muchas veces toma valores reales, a veces hay que realizar cierta transformacion para poder usarlo como parametro de una distribucion. Ejemplo: si estoy relacionando una variable continua como el largo de una hoja y quiero usar una regresion logistica para clasificar la planta entre dos tipos, al factor lineal lo debo convertir en una probabilidad [0, 1]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Un GLM jerarquico es un tipo de regresion lineal en el cual, frente a la presencia de subgrupos relacionados en mis datos, se utilizan hiperpriors para aprovechar esa informacion (esa relacion aporta informacion, por ejemplo, tener poblaciones de pinguinos de distintas especies; si bien son levemente distintos, por eso las subespecies, son pinguinos, por lo que son bastante parecidos, lo suficiente para que eso aporte informacion sobre, por ejemplo, como son las distribuciones de los largos de sus picos en funcion de su masa corporal)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "estadistica2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
